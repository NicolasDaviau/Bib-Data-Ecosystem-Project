# **Big Data project technical project**

## **Overview**  
This repository contains the materials for our distributed systems project. The goal of the project was to build a data processing pipeline using open-source tools (Apache Spark, Apache Hadoop, and Kibana) on an AWS EMR ecosystem.  

In this project, we designed and implemented a scalable data processing pipeline using open-source distributed systems:
Apache Spark
Apache Hadoop
Kibana and Elasticsearch
AWS s3 / Ec2 / EMR

---

## **All is in the PDF **  
The Report file is [Big-Data-Ecosystem-Report](Big-Data-Ecosystem-Report.pdf) We decided to present our project report in the format of slides (Canevas slides in pdf format). This approach allowed us to:  
1. **Combine visuals and explanations more effectively**, making it easier to show how the pipeline works.  
2. Make the content **clearer and more engaging** for readers who want to quickly understand the project.  

You can find the slides in this repository for a complete explanation of the project, including architecture diagrams, challenges, and conclusions.  

---

## **Whatâ€™s in This Repository?**  

1. **Code**:  
   - The Python script is an example for a data transformation task executed on the EMR cluster is included. This script demonstrates how raw CSV data is processed and transformed into JSON format using Spark.  
   - The script also illustrates how intermediate storage within HDFS is used before uploading the final results to S3.  

2. **Data**:  
   - A sample CSV file is provided to showcase the functionality of the pipeline. This data is used as input for the transformation and visualization steps.  

3. **Slides**:  
   - The complete project report in slide format, covering the objectives, architecture, implementation, challenges, and conclusions.  

---

Nicolas D'Aviau de Ternay and Louis Cagi Nicolau
